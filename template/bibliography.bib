@inproceedings{reid2025linear,
  title={Linear Transformer Topological Masking with Graph Random Features},
  author={Isaac Reid and Kumar Avinava Dubey and Deepali Jain and William F Whitney and Amr Ahmed and Joshua Ainslie and Alex Bewley and Mithun George Jacob and Aranyak Mehta and David Rendleman and Connor Schenck and Richard E. Turner and Ren{\'e} Wagner and Adrian Weller and Krzysztof Marcin Choromanski},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=6MBqQLp17E}
}

@inproceedings{vaswani2017attention,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N Gomez and \L{}ukasz Kaiser and Illia Polosukhin},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017},
  url={https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}
}

@inproceedings{ying2021do,
  title={Do Transformers Really Perform Badly for Graph Representation?},
  author={Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28877--28888},
  year={2021},
  url={https://proceedings.neurips.cc/paper/2021/hash/f1c1592588411002af340cbaedd6fc33-Abstract.html}
}

@inproceedings{choromanski2022rethinking,
  title={From Block-Toeplitz Matrices to Differential Equations on Graphs: Towards a General Theory for Scalable Masked Transformers},
  author={Krzysztof Choromanski and Han Lin and Haoxian Chen and Tianyi Zhang and Arijit Sehanobish and Valerii Likhosherstov and Jack Parker-Holder and Tamas Sarlos and Adrian Weller and Thomas Weingarten},
  booktitle={International Conference on Machine Learning},
  pages={3962--3983},
  year={2022},
  organization={PMLR},
  url={https://proceedings.mlr.press/v162/choromanski22a.html}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention},
  author={Angelos Katharopoulos and Apoorv Vyas and Nikolaos Pappas and Fran\c{c}ois Fleuret},
  booktitle={International Conference on Machine Learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR},
  url={https://proceedings.mlr.press/v119/katharopoulos20a.html}
}