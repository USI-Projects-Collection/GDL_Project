{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport networkx as nx\nimport time\n\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T22:07:02.830375Z","iopub.execute_input":"2025-12-10T22:07:02.830647Z","iopub.status.idle":"2025-12-10T22:07:12.332482Z","shell.execute_reply.started":"2025-12-10T22:07:02.830627Z","shell.execute_reply":"2025-12-10T22:07:12.331940Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --- ATTENTION MODULES ---\n\nclass SoftmaxAttention(nn.Module):\n    def __init__(self, dim, num_heads):\n        super().__init__()\n        self.num_heads = num_heads\n        self.scale = (dim // num_heads) ** -0.5\n        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.to_out = nn.Linear(dim, dim)\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: t.reshape(B, N, self.num_heads, -1).transpose(1, 2), qkv)\n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        return self.to_out(out)\n\nclass LinearAttention(nn.Module):\n    def __init__(self, dim, num_heads):\n        super().__init__()\n        self.num_heads = num_heads\n        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.to_out = nn.Linear(dim, dim)\n        self.eps = 1e-6\n\n    def feature_map(self, x):\n        return torch.nn.functional.relu(x) + self.eps\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: t.reshape(B, N, self.num_heads, -1).transpose(1, 2), qkv)\n        q = self.feature_map(q)\n        k = self.feature_map(k)\n        kv = k.transpose(-2, -1) @ v\n        z = 1 / (q @ k.sum(dim=-2, keepdim=True).transpose(-2, -1) + self.eps)\n        out = (q @ kv) * z\n        out = out.transpose(1, 2).reshape(B, N, C)\n        return self.to_out(out)\n\nclass GRFExactAttention(nn.Module):\n    def __init__(self, dim, num_heads, num_patches, n_walks, p_halt, device):\n        super().__init__()\n        self.num_heads = num_heads\n        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.to_out = nn.Linear(dim, dim)\n        self.eps = 1e-6\n        self.register_buffer('mask', self._generate_grf_mask(num_patches, n_walks, p_halt, device))\n\n    def _generate_grf_mask(self, N, n_walks, p_halt, device):\n        side = int(np.sqrt(N))\n        G = nx.grid_2d_graph(side, side)\n        mapping = {node: i for i, node in enumerate(sorted(list(G.nodes())))}\n        G = nx.relabel_nodes(G, mapping)\n        mask = torch.zeros(N, N)\n        for start_node in range(N):\n            for _ in range(n_walks):\n                curr = start_node\n                while True:\n                    mask[start_node, curr] += 1.0\n                    if np.random.rand() < p_halt: break\n                    neighbors = sorted(list(G.neighbors(curr)))\n                    if not neighbors: break\n                    curr = np.random.choice(neighbors)\n            mask[start_node] /= max(n_walks, 1)\n        return mask.to(device)\n\n    def feature_map(self, x):\n        return torch.nn.functional.relu(x) + self.eps\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: t.reshape(B, N, self.num_heads, -1).transpose(1, 2), qkv)\n        q = self.feature_map(q)\n        k = self.feature_map(k)\n\n        q_graph = (q.transpose(-2, -1) @ self.mask).transpose(-2, -1)\n        k_graph = (k.transpose(-2, -1) @ self.mask).transpose(-2, -1)\n        q = q + 0.1 * q_graph\n        k = k + 0.1 * k_graph\n\n        linear_kernel = q @ k.transpose(-2, -1)\n        masked_kernel = linear_kernel * self.mask.unsqueeze(0).unsqueeze(0)\n        z = 1 / (masked_kernel.sum(dim=-1, keepdim=True) + self.eps)\n        out = (masked_kernel @ v) * z\n        out = out.transpose(1, 2).reshape(B, N, C)\n        return self.to_out(out)\n\nclass MAlphaAttention(nn.Module):\n    def __init__(self, dim, num_heads, num_patches, device, order=5, decay=0.5):\n        super().__init__()\n        self.num_heads = num_heads\n        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.to_out = nn.Linear(dim, dim)\n        self.eps = 1e-6\n        self.register_buffer('mask', self._generate_exact_mask(num_patches, order, decay, device))\n\n    def _generate_exact_mask(self, N, order, decay, device):\n        side = int(np.sqrt(N))\n        G = nx.grid_2d_graph(side, side)\n        mapping = {node: i for i, node in enumerate(sorted(list(G.nodes())))}\n        G = nx.relabel_nodes(G, mapping)\n        A = nx.to_numpy_array(G)\n        D_inv = np.diag(1.0 / np.maximum(A.sum(axis=1), 1))\n        W = D_inv @ A\n        M = np.eye(N)\n        W_k = np.eye(N)\n        coeff = 1.0\n        for _ in range(order):\n            W_k = W_k @ W\n            coeff *= decay\n            M += coeff * W_k\n        M = M / M.sum(axis=1, keepdims=True)\n        return torch.tensor(M, dtype=torch.float32).to(device)\n\n    def feature_map(self, x):\n        return torch.nn.functional.relu(x) + self.eps\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: t.reshape(B, N, self.num_heads, -1).transpose(1, 2), qkv)\n        q = self.feature_map(q)\n        k = self.feature_map(k)\n        q_graph = (q.transpose(-2, -1) @ self.mask).transpose(-2, -1)\n        k_graph = (k.transpose(-2, -1) @ self.mask).transpose(-2, -1)\n        q = q + 0.1 * q_graph\n        k = k + 0.1 * k_graph\n        linear_kernel = q @ k.transpose(-2, -1)\n        masked_kernel = linear_kernel * self.mask.unsqueeze(0).unsqueeze(0)\n        z = 1 / (masked_kernel.sum(dim=-1, keepdim=True) + self.eps)\n        out = (masked_kernel @ v) * z\n        out = out.transpose(1, 2).reshape(B, N, C)\n        return self.to_out(out)\n\nclass ToeplitzAttention(nn.Module):\n    def __init__(self, dim, num_heads, num_patches, device, decay=0.8):\n        super().__init__()\n        self.num_heads = num_heads\n        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.to_out = nn.Linear(dim, dim)\n        self.eps = 1e-6\n        self.register_buffer('mask', self._generate_toeplitz_mask(num_patches, decay, device))\n\n    def _generate_toeplitz_mask(self, N, decay, device):\n        side = int(np.sqrt(N))\n        mask = np.zeros((N, N))\n        for i in range(N):\n            for j in range(N):\n                xi, yi = i // side, i % side\n                xj, yj = j // side, j % side\n                dist = abs(xi - xj) + abs(yi - yj)\n                mask[i, j] = decay ** dist\n        mask = mask / mask.sum(axis=1, keepdims=True)\n        return torch.tensor(mask, dtype=torch.float32).to(device)\n\n    def feature_map(self, x):\n        return torch.nn.functional.relu(x) + self.eps\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: t.reshape(B, N, self.num_heads, -1).transpose(1, 2), qkv)\n        q = self.feature_map(q)\n        k = self.feature_map(k)\n        q_graph = (q.transpose(-2, -1) @ self.mask).transpose(-2, -1)\n        k_graph = (k.transpose(-2, -1) @ self.mask).transpose(-2, -1)\n        q = q + 0.1 * q_graph\n        k = k + 0.1 * k_graph\n        linear_kernel = q @ k.transpose(-2, -1)\n        masked_kernel = linear_kernel * self.mask.unsqueeze(0).unsqueeze(0)\n        z = 1 / (masked_kernel.sum(dim=-1, keepdim=True) + self.eps)\n        out = (masked_kernel @ v) * z\n        out = out.transpose(1, 2).reshape(B, N, C)\n        return self.to_out(out)\n\n# --- 4. MODEL ---\nclass ViT(nn.Module):\n    def __init__(self, patch_size, image_size, dim, depth, num_heads, dropout, mlp_dim, device, channels=3, attention_type='softmax', n_walks=50, p_halt=0.1, num_classes=10):\n        super().__init__()\n        self.patch_size = patch_size\n        self.channels = channels\n        num_patches = (image_size // patch_size) ** 2\n        patch_dim = channels * patch_size ** 2\n        self.patch_embed = nn.Linear(patch_dim, dim)\n        self.pos_embed = nn.Parameter(torch.randn(1, num_patches, dim))\n        self.layers = nn.ModuleList([])\n\n        for _ in range(depth):\n            if attention_type == 'softmax':\n                attn = SoftmaxAttention(dim, num_heads)\n            elif attention_type == 'linear':\n                attn = LinearAttention(dim, num_heads)\n            elif attention_type == 'grf':\n                attn = GRFExactAttention(dim, num_heads, num_patches, n_walks, p_halt, device)\n            elif attention_type == 'm_alpha':\n                attn = MAlphaAttention(dim, num_heads, num_patches, device)\n            elif attention_type == 'toeplitz':\n                attn = ToeplitzAttention(dim, num_heads, num_patches, device)\n\n            self.layers.append(nn.ModuleList([\n                nn.LayerNorm(dim),\n                attn,\n                nn.LayerNorm(dim),\n                nn.Sequential(\n                    nn.Linear(dim, mlp_dim), nn.GELU(), nn.Dropout(dropout),\n                    nn.Linear(mlp_dim, dim), nn.Dropout(dropout)\n                )\n            ]))\n        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, num_classes))\n\n    def forward(self, img):\n        p = self.patch_size\n        x = img.unfold(2, p, p).unfold(3, p, p).reshape(img.shape[0], -1, self.channels * p * p)\n        x = self.patch_embed(x)\n        B, N, _ = x.shape\n        x += self.pos_embed[:, :N]\n        for norm1, attn, norm2, mlp in self.layers:\n            x = x + attn(norm1(x))\n            x = x + mlp(norm2(x))\n        return self.mlp_head(x.mean(dim=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T22:07:13.964222Z","iopub.execute_input":"2025-12-10T22:07:13.965098Z","iopub.status.idle":"2025-12-10T22:07:13.996786Z","shell.execute_reply.started":"2025-12-10T22:07:13.965069Z","shell.execute_reply":"2025-12-10T22:07:13.995941Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def get_dataloaders(dataset_name, batch_size, resize_image=32, manipulate_images=False):\n    transform_compose_list = [\n            transforms.Resize((resize_image, resize_image)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ]\n\n    if manipulate_images:\n        transform_compose_list = [\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomCrop(resize_image, padding=4),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n        ] + transform_compose_list\n        \n    if 'mnist' in dataset_name.lower():\n        # Resize to 32x32 to match patch logic easily\n        transform_compose_list = transform_compose_list[:-1] + [transforms.Normalize((0.5,), (0.5,))]\n\n    transform = transforms.Compose(transform_compose_list)\n        \n    if dataset_name.lower() == 'cifar10':\n        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n        num_classes = 10\n        channels = 3\n    elif dataset_name.lower() == 'cifar100':\n        trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n        testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n        num_classes = 100\n        channels = 3\n    elif dataset_name.lower() == 'mnist':\n        trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n        testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n        num_classes = 10\n        channels = 1\n    elif dataset_name.lower() == 'fashionmnist':\n        trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n        testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n        num_classes = 10\n        channels = 1\n    else:\n        raise ValueError(\"Unknown dataset\")\n\n    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n\n    return trainloader, testloader, num_classes, channels\n\n\n# --- 1. CONFIGURATION ---\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nEPOCHS = 15\nIMAGE_SIZE = 32\nPATCH_SIZE = 4\nDIM = 64\nDEPTH = 2\nNUM_HEADS = 4\nMLP_DIM = 128\nDROPOUT = 0.1\n\nif torch.cuda.is_available():\n    DEVICE = torch.device(\"cuda\")\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device(\"mps\")\nelse:\n    DEVICE = torch.device(\"cpu\")\n\nprint(f\"Using Device: {DEVICE}\")\n\ndef train_and_evaluate(model_type, dataset_name='cifar10', n_walks=50, p_halt=0.1, manipulate_images=False):\n    print(f\"\\n--- Training {model_type.upper()} on {dataset_name.upper()} ---\")\n\n    trainloader, testloader, num_classes, channels = get_dataloaders(dataset_name, BATCH_SIZE, manipulate_images=manipulate_images)\n\n    model = ViT(\n        patch_size=PATCH_SIZE,\n        image_size=IMAGE_SIZE,\n        dim=DIM,\n        depth=DEPTH,\n        num_heads=NUM_HEADS,\n        dropout=DROPOUT,\n        mlp_dim=MLP_DIM,\n        device=DEVICE,\n        channels=channels,\n        attention_type=model_type,\n        n_walks=n_walks,\n        p_halt=p_halt,\n        num_classes=num_classes\n    )\n\n    model = model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n\n    start_time = time.time()\n\n    # --- TRAINING LOOP WITH PER-EPOCH LOGGING ---\n    final_acc = 0.0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        for images, labels in trainloader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        avg_train_loss = running_loss / len(trainloader)\n\n        # Evaluate after every epoch\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in testloader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        epoch_acc = 100 * correct / total\n        final_acc = epoch_acc # Store last accuracy\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_train_loss:.4f} | Test Acc: {epoch_acc:.2f}%\")\n\n    train_time = time.time() - start_time\n    print(f\"   -> Final Result: Acc = {final_acc:.2f}%\")\n    return final_acc\n\ndef replicate_table_1_complete(dataset_name, manipulate_images=False):\n    print(\"\\n\" + \"=\"*70)\n    print(f\"5.2 Visual transformer training on {dataset_name}\")\n    print(\"=\"*70)\n\n    acc_softmax = train_and_evaluate('softmax', dataset_name=dataset_name, manipulate_images=manipulate_images)\n    acc_toeplitz = train_and_evaluate('toeplitz', dataset_name=dataset_name, manipulate_images=manipulate_images)\n    acc_m_alpha = train_and_evaluate('m_alpha', dataset_name=dataset_name, manipulate_images=manipulate_images)\n    acc_grf = train_and_evaluate('grf', dataset_name=dataset_name, n_walks=50, p_halt=0.1, manipulate_images=manipulate_images)\n    acc_linear = train_and_evaluate('linear', dataset_name=dataset_name, manipulate_images=manipulate_images)\n\n    print(f\"\\nCOMPLETE RESULT - {dataset_name}\")\n    print(f\"{'Method':<25} {'Accuracy':<10}\")\n    print(\"-\" * 50)\n    print(f\"{'Unmasked Softmax':<25} {acc_softmax:<10.2f} \")\n    print(f\"{'Toeplitz-masked Linear':<25} {acc_toeplitz:<10.2f}\")\n    print(f\"{'M_alpha(G)-masked':<25} {acc_m_alpha:<10.2f} \")\n    print(\"-\" * 50)\n    print(f\"{'GRF-masked Linear':<25} {acc_grf:<10.2f}\")\n    print(f\"{'Unmasked Linear':<25} {acc_linear:<10.2f}\")\n    print(\"=\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T22:07:20.505061Z","iopub.execute_input":"2025-12-10T22:07:20.505690Z","iopub.status.idle":"2025-12-10T22:07:20.577473Z","shell.execute_reply.started":"2025-12-10T22:07:20.505653Z","shell.execute_reply":"2025-12-10T22:07:20.576699Z"}},"outputs":[{"name":"stdout","text":"Using Device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## CIFAR10 - 15 EPOCHS","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nEPOCHS = 15\nIMAGE_SIZE = 32\nPATCH_SIZE = 4\nDIM = 64\nDEPTH = 2\nNUM_HEADS = 4\nMLP_DIM = 128\nDROPOUT = 0.1\nDATASET_NAME = 'cifar10'\n\ndef train_and_evaluate(model_type, dataset_name='cifar10', n_walks=50, p_halt=0.1, manipulate_images=False):\n    print(f\"\\n--- Training {model_type.upper()} on {dataset_name.upper()} ---\")\n\n    trainloader, testloader, num_classes, channels = get_dataloaders(dataset_name, BATCH_SIZE,manipulate_images=manipulate_images)\n\n    model = ViT(\n        patch_size=PATCH_SIZE,\n        image_size=IMAGE_SIZE,\n        dim=DIM,\n        depth=DEPTH,\n        num_heads=NUM_HEADS,\n        dropout=DROPOUT,\n        mlp_dim=MLP_DIM,\n        device=DEVICE,\n        channels=channels,\n        attention_type=model_type,\n        n_walks=n_walks,\n        p_halt=p_halt,\n        num_classes=num_classes\n    )\n\n    model = model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n\n    start_time = time.time()\n\n    # --- TRAINING LOOP WITH PER-EPOCH LOGGING ---\n    final_acc = 0.0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        for images, labels in trainloader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        avg_train_loss = running_loss / len(trainloader)\n\n        # Evaluate after every epoch\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in testloader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        epoch_acc = 100 * correct / total\n        final_acc = epoch_acc # Store last accuracy\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_train_loss:.4f} | Test Acc: {epoch_acc:.2f}%\")\n\n    train_time = time.time() - start_time\n    print(f\"   -> Final Result: Acc = {final_acc:.2f}%\")\n    return final_acc\n\nif __name__ == \"__main__\":\n    replicate_table_1_complete(DATASET_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:14:44.269903Z","iopub.execute_input":"2025-12-10T16:14:44.270160Z","iopub.status.idle":"2025-12-10T16:25:38.562782Z","shell.execute_reply.started":"2025-12-10T16:14:44.270132Z","shell.execute_reply":"2025-12-10T16:25:38.561540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CIFAR100 - 30 EPOCHS","metadata":{}},{"cell_type":"code","source":"# --- 1. CONFIGURATION ---\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nEPOCHS = 30\nIMAGE_SIZE = 32\nPATCH_SIZE = 4\nDIM = 64\nDEPTH = 2\nNUM_HEADS = 4\nMLP_DIM = 128\nDROPOUT = 0.1\n\n# --- DATASET SELECTION ---\n# Switch to 'CIFAR100' for a harder task\nDATASET_NAME = 'CIFAR100'  # Options: 'CIFAR10', 'CIFAR100'\n\nif torch.cuda.is_available():\n    DEVICE = torch.device(\"cuda\")\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device(\"mps\")\nelse:\n    DEVICE = torch.device(\"cpu\")\n\nprint(f\"Using Device: {DEVICE}\")\nprint(f\"Dataset: {DATASET_NAME}\")\n\n# --- 5. TRAINING UTILS ---\ndef train_and_evaluate(model_type, dataset_name='cifar10', n_walks=50, p_halt=0.1, manipulate_images=False):\n    print(f\"\\n--- Training {model_type.upper()} on {dataset_name.upper()} ---\")\n\n    trainloader, testloader, num_classes, channels = get_dataloaders(dataset_name, BATCH_SIZE,manipulate_images=manipulate_images)\n\n    model = ViT(\n        patch_size=PATCH_SIZE,\n        image_size=IMAGE_SIZE,\n        dim=DIM,\n        depth=DEPTH,\n        num_heads=NUM_HEADS,\n        dropout=DROPOUT,\n        mlp_dim=MLP_DIM,\n        device=DEVICE,\n        channels=channels,\n        attention_type=model_type,\n        n_walks=n_walks,\n        p_halt=p_halt,\n        num_classes=num_classes\n    )\n\n    model = model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n\n    start_time = time.time()\n\n    # --- TRAINING LOOP WITH PER-EPOCH LOGGING ---\n    final_acc = 0.0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        for images, labels in trainloader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        avg_train_loss = running_loss / len(trainloader)\n\n        # Evaluate after every epoch\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in testloader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        epoch_acc = 100 * correct / total\n        final_acc = epoch_acc # Store last accuracy\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_train_loss:.4f} | Test Acc: {epoch_acc:.2f}%\")\n\n    train_time = time.time() - start_time\n    print(f\"   -> Final Result: Acc = {final_acc:.2f}%\")\n    return final_acc\n# TODO Rename title in output\n\nif __name__ == \"__main__\":\n    replicate_table_1_complete(DATASET_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:26:17.939853Z","iopub.execute_input":"2025-12-10T16:26:17.940136Z","iopub.status.idle":"2025-12-10T16:26:52.377097Z","shell.execute_reply.started":"2025-12-10T16:26:17.940114Z","shell.execute_reply":"2025-12-10T16:26:52.376129Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CIFAR10 - 30 EPOCHS","metadata":{}},{"cell_type":"code","source":"# --- 1. CONFIGURATION ---\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nEPOCHS = 30\nIMAGE_SIZE = 32\nPATCH_SIZE = 4\nDIM = 64\nDEPTH = 2\nNUM_HEADS = 4\nMLP_DIM = 128\nDROPOUT = 0.1\n\n# --- DATASET SELECTION ---\n# Switch to 'CIFAR100' for a harder task\nDATASET_NAME = 'CIFAR10'  # Options: 'CIFAR10', 'CIFAR100'\n\nif torch.cuda.is_available():\n    DEVICE = torch.device(\"cuda\")\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device(\"mps\")\nelse:\n    DEVICE = torch.device(\"cpu\")\n\nprint(f\"Using Device: {DEVICE}\")\nprint(f\"Dataset: {DATASET_NAME}\")\n\n# --- 5. TRAINING UTILS ---\ndef train_and_evaluate(model_type, dataset_name='cifar10', n_walks=50, p_halt=0.1, manipulate_images=False):\n    print(f\"\\n--- Training {model_type.upper()} on {dataset_name.upper()} ---\")\n\n    trainloader, testloader, num_classes, channels = get_dataloaders(dataset_name, BATCH_SIZE,manipulate_images=manipulate_images)\n\n    model = ViT(\n        patch_size=PATCH_SIZE,\n        image_size=IMAGE_SIZE,\n        dim=DIM,\n        depth=DEPTH,\n        num_heads=NUM_HEADS,\n        dropout=DROPOUT,\n        mlp_dim=MLP_DIM,\n        device=DEVICE,\n        channels=channels,\n        attention_type=model_type,\n        n_walks=n_walks,\n        p_halt=p_halt,\n        num_classes=num_classes\n    )\n\n    model = model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n\n    start_time = time.time()\n\n    # --- TRAINING LOOP WITH PER-EPOCH LOGGING ---\n    final_acc = 0.0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        for images, labels in trainloader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        avg_train_loss = running_loss / len(trainloader)\n\n        # Evaluate after every epoch\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in testloader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        epoch_acc = 100 * correct / total\n        final_acc = epoch_acc # Store last accuracy\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_train_loss:.4f} | Test Acc: {epoch_acc:.2f}%\")\n\n    train_time = time.time() - start_time\n    print(f\"   -> Final Result: Acc = {final_acc:.2f}%\")\n    return final_acc\n# TODO Rename title in output\n\nif __name__ == \"__main__\":\n    replicate_table_1_complete(DATASET_NAME)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## FashionMNIST - 10 EPOCHS","metadata":{}},{"cell_type":"code","source":"# --- 1. CONFIGURATION ---\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nEPOCHS = 10\nIMAGE_SIZE = 32\nPATCH_SIZE = 4\nDIM = 64\nDEPTH = 2\nNUM_HEADS = 4\nMLP_DIM = 128\nDROPOUT = 0.1\n\n# --- DATASET SELECTION ---\n# Switch to 'CIFAR100' for a harder task\nDATASET_NAME = 'FashionMNIST'  # Options: 'CIFAR10', 'CIFAR100', 'FashionMNIST', 'MNIST'\n\nif torch.cuda.is_available():\n    DEVICE = torch.device(\"cuda\")\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device(\"mps\")\nelse:\n    DEVICE = torch.device(\"cpu\")\n\nprint(f\"Using Device: {DEVICE}\")\nprint(f\"Dataset: {DATASET_NAME}\")\n\n# --- 5. TRAINING UTILS ---\ndef train_and_evaluate(model_type, dataset_name='cifar10', n_walks=50, p_halt=0.1, manipulate_images=False):\n    print(f\"\\n--- Training {model_type.upper()} on {dataset_name.upper()} ---\")\n\n    trainloader, testloader, num_classes, channels = get_dataloaders(dataset_name, BATCH_SIZE,manipulate_images=manipulate_images)\n\n    model = ViT(\n        patch_size=PATCH_SIZE,\n        image_size=IMAGE_SIZE,\n        dim=DIM,\n        depth=DEPTH,\n        num_heads=NUM_HEADS,\n        dropout=DROPOUT,\n        mlp_dim=MLP_DIM,\n        device=DEVICE,\n        channels=channels,\n        attention_type=model_type,\n        n_walks=n_walks,\n        p_halt=p_halt,\n        num_classes=num_classes\n    )\n\n\n    model = model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n\n    start_time = time.time()\n\n    # --- TRAINING LOOP WITH PER-EPOCH LOGGING ---\n    final_acc = 0.0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        for images, labels in trainloader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        avg_train_loss = running_loss / len(trainloader)\n\n        # Evaluate after every epoch\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in testloader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        epoch_acc = 100 * correct / total\n        final_acc = epoch_acc # Store last accuracy\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_train_loss:.4f} | Test Acc: {epoch_acc:.2f}%\")\n\n    train_time = time.time() - start_time\n    print(f\"   -> Final Result: Acc = {final_acc:.2f}%\")\n    return final_acc\n# TODO Rename title in output\n\nif __name__ == \"__main__\":\n    replicate_table_1_complete(DATASET_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T16:25:38.563270Z","iopub.status.idle":"2025-12-10T16:25:38.563506Z","shell.execute_reply.started":"2025-12-10T16:25:38.563387Z","shell.execute_reply":"2025-12-10T16:25:38.563396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CIFAR10 - 15 EPOCHS - different parameters (batch_size, image_size, patch_size, depth)","metadata":{}},{"cell_type":"code","source":"# --- 1. CONFIGURATION ---\nBATCH_SIZE = 64\nLEARNING_RATE = 1e-3\nEPOCHS = 15\nIMAGE_SIZE = 42\nPATCH_SIZE = 4\nDIM = 64\nDEPTH = 4\nNUM_HEADS = 4\nMLP_DIM = 128\nDROPOUT = 0.1\nN_WALKS = 100\nP_HALT = 0.1\n\n# --- DATASET SELECTION ---\n# Switch to 'CIFAR100' for a harder task\nDATASET_NAME = \"CIFAR10\"  # Options: 'CIFAR10', 'CIFAR100', 'FashionMNIST', 'MNIST'\n\nif torch.cuda.is_available():\n    DEVICE = torch.device(\"cuda\")\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device(\"mps\")\nelse:\n    DEVICE = torch.device(\"cpu\")\n\nprint(f\"Using Device: {DEVICE}\")\nprint(f\"Dataset: {DATASET_NAME}\")\n\n\n# --- 5. TRAINING UTILS ---\ndef train_and_evaluate(\n    model_type, dataset_name=\"cifar10\", n_walks=50, p_halt=0.1, manipulate_images=False\n):\n    print(f\"\\n--- Training {model_type.upper()} on {dataset_name.upper()} ---\")\n\n    trainloader, testloader, num_classes, channels = get_dataloaders(\n        dataset_name,\n        BATCH_SIZE,\n        manipulate_images=manipulate_images,\n        resize_image=IMAGE_SIZE,\n    )\n\n    model = ViT(\n        patch_size=PATCH_SIZE,\n        image_size=IMAGE_SIZE,\n        dim=DIM,\n        depth=DEPTH,\n        num_heads=NUM_HEADS,\n        dropout=DROPOUT,\n        mlp_dim=MLP_DIM,\n        device=DEVICE,\n        channels=channels,\n        attention_type=model_type,\n        n_walks=n_walks,\n        p_halt=p_halt,\n        num_classes=num_classes,\n    )\n\n\n    model = model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n\n    start_time = time.time()\n\n    # --- TRAINING LOOP WITH PER-EPOCH LOGGING ---\n    final_acc = 0.0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        for images, labels in trainloader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        avg_train_loss = running_loss / len(trainloader)\n\n        # Evaluate after every epoch\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in testloader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        epoch_acc = 100 * correct / total\n        final_acc = epoch_acc  # Store last accuracy\n\n        print(\n            f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_train_loss:.4f} | Test Acc: {epoch_acc:.2f}%\"\n        )\n\n    train_time = time.time() - start_time\n    print(f\"   -> Final Result: Acc = {final_acc:.2f}%\")\n    return final_acc\n\n\n# TODO Rename title in output\n\ndef replicate_table_1_complete(dataset_name, n_walks, p_halt, manipulate_images=False):\n    print(\"\\n\" + \"=\"*70)\n    print(f\"5.2 Visual transformer training on {dataset_name}\")\n    print(\"=\"*70)\n\n    acc_softmax = train_and_evaluate('softmax', dataset_name=dataset_name, manipulate_images=manipulate_images)\n    acc_toeplitz = train_and_evaluate('toeplitz', dataset_name=dataset_name, manipulate_images=manipulate_images)\n    acc_m_alpha = train_and_evaluate('m_alpha', dataset_name=dataset_name, manipulate_images=manipulate_images)\n    acc_grf = train_and_evaluate('grf', dataset_name=dataset_name, n_walks=n_walks, p_halt=p_halt, manipulate_images=manipulate_images)\n    acc_linear = train_and_evaluate('linear', dataset_name=dataset_name, manipulate_images=manipulate_images)\n\n    print(f\"\\nCOMPLETE RESULT - {dataset_name}\")\n    print(f\"{'Method':<25} {'Accuracy':<10}\")\n    print(\"-\" * 50)\n    print(f\"{'Unmasked Softmax':<25} {acc_softmax:<10.2f} \")\n    print(f\"{'Toeplitz-masked Linear':<25} {acc_toeplitz:<10.2f}\")\n    print(f\"{'M_alpha(G)-masked':<25} {acc_m_alpha:<10.2f} \")\n    print(\"-\" * 50)\n    print(f\"{'GRF-masked Linear':<25} {acc_grf:<10.2f}\")\n    print(f\"{'Unmasked Linear':<25} {acc_linear:<10.2f}\")\n    print(\"=\"*70)\n\nif __name__ == \"__main__\":\n    replicate_table_1_complete(DATASET_NAME, N_WALKS, P_HALT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T22:07:28.390023Z","iopub.execute_input":"2025-12-10T22:07:28.390686Z","iopub.status.idle":"2025-12-10T22:41:30.082249Z","shell.execute_reply.started":"2025-12-10T22:07:28.390663Z","shell.execute_reply":"2025-12-10T22:41:30.081589Z"}},"outputs":[{"name":"stdout","text":"Using Device: cuda\nDataset: CIFAR10\n\n======================================================================\n5.2 Visual transformer training on CIFAR10\n======================================================================\n\n--- Training SOFTMAX on CIFAR10 ---\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:05<00:00, 28.7MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15 | Loss: 1.8496 | Test Acc: 42.40%\nEpoch 2/15 | Loss: 1.5206 | Test Acc: 46.95%\nEpoch 3/15 | Loss: 1.4078 | Test Acc: 50.05%\nEpoch 4/15 | Loss: 1.3361 | Test Acc: 49.56%\nEpoch 5/15 | Loss: 1.2800 | Test Acc: 52.41%\nEpoch 6/15 | Loss: 1.2350 | Test Acc: 53.77%\nEpoch 7/15 | Loss: 1.1895 | Test Acc: 52.02%\nEpoch 8/15 | Loss: 1.1520 | Test Acc: 54.61%\nEpoch 9/15 | Loss: 1.1141 | Test Acc: 55.36%\nEpoch 10/15 | Loss: 1.0784 | Test Acc: 55.44%\nEpoch 11/15 | Loss: 1.0444 | Test Acc: 55.81%\nEpoch 12/15 | Loss: 1.0096 | Test Acc: 56.54%\nEpoch 13/15 | Loss: 0.9797 | Test Acc: 56.33%\nEpoch 14/15 | Loss: 0.9469 | Test Acc: 56.55%\nEpoch 15/15 | Loss: 0.9225 | Test Acc: 56.42%\n   -> Final Result: Acc = 56.42%\n\n--- Training TOEPLITZ on CIFAR10 ---\nEpoch 1/15 | Loss: 1.8154 | Test Acc: 43.01%\nEpoch 2/15 | Loss: 1.5184 | Test Acc: 47.63%\nEpoch 3/15 | Loss: 1.4132 | Test Acc: 49.49%\nEpoch 4/15 | Loss: 1.3396 | Test Acc: 51.25%\nEpoch 5/15 | Loss: 1.2820 | Test Acc: 54.27%\nEpoch 6/15 | Loss: 1.2316 | Test Acc: 54.02%\nEpoch 7/15 | Loss: 1.1849 | Test Acc: 56.40%\nEpoch 8/15 | Loss: 1.1401 | Test Acc: 57.39%\nEpoch 9/15 | Loss: 1.1037 | Test Acc: 56.99%\nEpoch 10/15 | Loss: 1.0693 | Test Acc: 57.68%\nEpoch 11/15 | Loss: 1.0393 | Test Acc: 58.07%\nEpoch 12/15 | Loss: 1.0069 | Test Acc: 57.07%\nEpoch 13/15 | Loss: 0.9774 | Test Acc: 59.07%\nEpoch 14/15 | Loss: 0.9551 | Test Acc: 59.26%\nEpoch 15/15 | Loss: 0.9199 | Test Acc: 57.90%\n   -> Final Result: Acc = 57.90%\n\n--- Training M_ALPHA on CIFAR10 ---\nEpoch 1/15 | Loss: 1.8397 | Test Acc: 42.41%\nEpoch 2/15 | Loss: 1.5375 | Test Acc: 46.83%\nEpoch 3/15 | Loss: 1.4361 | Test Acc: 50.91%\nEpoch 4/15 | Loss: 1.3640 | Test Acc: 47.79%\nEpoch 5/15 | Loss: 1.3113 | Test Acc: 52.66%\nEpoch 6/15 | Loss: 1.2711 | Test Acc: 53.09%\nEpoch 7/15 | Loss: 1.2257 | Test Acc: 54.68%\nEpoch 8/15 | Loss: 1.1937 | Test Acc: 54.26%\nEpoch 9/15 | Loss: 1.1644 | Test Acc: 54.40%\nEpoch 10/15 | Loss: 1.1282 | Test Acc: 57.09%\nEpoch 11/15 | Loss: 1.0985 | Test Acc: 57.20%\nEpoch 12/15 | Loss: 1.0684 | Test Acc: 57.02%\nEpoch 13/15 | Loss: 1.0472 | Test Acc: 58.28%\nEpoch 14/15 | Loss: 1.0120 | Test Acc: 58.83%\nEpoch 15/15 | Loss: 0.9903 | Test Acc: 58.95%\n   -> Final Result: Acc = 58.95%\n\n--- Training GRF on CIFAR10 ---\nEpoch 1/15 | Loss: 1.8559 | Test Acc: 40.18%\nEpoch 2/15 | Loss: 1.5532 | Test Acc: 46.04%\nEpoch 3/15 | Loss: 1.4456 | Test Acc: 49.78%\nEpoch 4/15 | Loss: 1.3716 | Test Acc: 50.96%\nEpoch 5/15 | Loss: 1.3120 | Test Acc: 53.50%\nEpoch 6/15 | Loss: 1.2592 | Test Acc: 54.55%\nEpoch 7/15 | Loss: 1.2169 | Test Acc: 55.89%\nEpoch 8/15 | Loss: 1.1742 | Test Acc: 56.82%\nEpoch 9/15 | Loss: 1.1382 | Test Acc: 55.11%\nEpoch 10/15 | Loss: 1.1065 | Test Acc: 57.09%\nEpoch 11/15 | Loss: 1.0737 | Test Acc: 57.24%\nEpoch 12/15 | Loss: 1.0428 | Test Acc: 58.42%\nEpoch 13/15 | Loss: 1.0165 | Test Acc: 57.12%\nEpoch 14/15 | Loss: 0.9901 | Test Acc: 58.70%\nEpoch 15/15 | Loss: 0.9590 | Test Acc: 58.93%\n   -> Final Result: Acc = 58.93%\n\n--- Training LINEAR on CIFAR10 ---\nEpoch 1/15 | Loss: 1.8134 | Test Acc: 42.36%\nEpoch 2/15 | Loss: 1.5152 | Test Acc: 47.23%\nEpoch 3/15 | Loss: 1.4215 | Test Acc: 50.62%\nEpoch 4/15 | Loss: 1.3586 | Test Acc: 51.89%\nEpoch 5/15 | Loss: 1.2864 | Test Acc: 52.76%\nEpoch 6/15 | Loss: 1.2407 | Test Acc: 51.27%\nEpoch 7/15 | Loss: 1.2008 | Test Acc: 54.97%\nEpoch 8/15 | Loss: 1.1655 | Test Acc: 55.55%\nEpoch 9/15 | Loss: 1.1296 | Test Acc: 56.20%\nEpoch 10/15 | Loss: 1.1004 | Test Acc: 56.84%\nEpoch 11/15 | Loss: 1.0954 | Test Acc: 57.38%\nEpoch 12/15 | Loss: 1.0824 | Test Acc: 58.40%\nEpoch 13/15 | Loss: 1.0588 | Test Acc: 59.06%\nEpoch 14/15 | Loss: 1.0098 | Test Acc: 59.50%\nEpoch 15/15 | Loss: 0.9816 | Test Acc: 59.58%\n   -> Final Result: Acc = 59.58%\n\nCOMPLETE RESULT - CIFAR10\nMethod                    Accuracy  \n--------------------------------------------------\nUnmasked Softmax          56.42      \nToeplitz-masked Linear    57.90     \nM_alpha(G)-masked         58.95      \n--------------------------------------------------\nGRF-masked Linear         58.93     \nUnmasked Linear           59.58     \n======================================================================\n","output_type":"stream"}],"execution_count":5}]}